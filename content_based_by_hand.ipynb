{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NnuRIZedJmK"
   },
   "source": [
    "## Content Based Filtering by hand\n",
    "\n",
    "This lab illustrates how to implement a content based filter using low level Tensorflow operations.  \n",
    "The code here follows the technique explained in Module 2 of Recommendation Engines: Content Based Filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 15 kB/s s eta 0:00:012    |███████████▎                    | 149.4 MB 65.9 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.19.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 60.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (3.12.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.30.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (3.2.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (0.34.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.12.1)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 46 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.1.2)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1) (1.0.8)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 36.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.1) (47.3.1.post20200616)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1) (2.10.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.25.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.8)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=cadab7ab4c4a8188afec96d9a4021dc1ba9cb2b3bf66a803de2d5a7078e6b2e9\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: witwidget 1.7.0 has requirement oauth2client>=4.1.3, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tfx 0.22.0 has requirement pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tfx-bsl 0.22.1 has requirement pyarrow<0.17,>=0.16.0, but you'll have pyarrow 0.17.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-model-analysis 0.22.2 has requirement pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-io 0.13.0 has requirement tensorflow<2.3.0,>=2.2.0, but you'll have tensorflow 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-data-validation 0.22.2 has requirement joblib<0.15,>=0.12, but you'll have joblib 0.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-data-validation 0.22.2 has requirement pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, scipy, astor, gast, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.0\n",
      "    Uninstalling scipy-1.5.0:\n",
      "      Successfully uninstalled scipy-1.5.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed astor-0.8.1 gast-0.2.2 scipy-1.4.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to restart your kernel to ensure this change has taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IzbZLmz1dJmL",
    "outputId": "f4f882d9-6752-4b8d-8d7d-83eb61690d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36uCjFhldJmR"
   },
   "source": [
    "To start, we'll create our list of users, movies and features. While the users and movies represent elements in our database, for a content-based filtering method the features of the movies are likely hand-engineered and rely on domain knowledge to provide the best embedding space. Here we use the categories of Action, Sci-Fi, Comedy, Cartoon, and Drama to describe our movies (and thus our users).\n",
    "\n",
    "In this example, we will assume our database consists of four users and six movies, listed below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElQV43fxdJmS"
   },
   "outputs": [],
   "source": [
    "users = ['Ryan', 'Danielle',  'Vijay', 'Chris']\n",
    "movies = ['Star Wars', 'The Dark Knight', 'Shrek', 'The Incredibles', 'Bleu', 'Memento']\n",
    "features = ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
    "\n",
    "num_users = len(users)\n",
    "num_movies = len(movies)\n",
    "num_feats = len(features)\n",
    "num_recommendations = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6iJCViqdJmU"
   },
   "source": [
    "### Initialize our users, movie ratings and features\n",
    "\n",
    "We'll need to enter the user's movie ratings and the k-hot encoded movie features matrix. Each row of the users_movies matrix represents a single user's rating (from 1 to 10) for each movie. A zero indicates that the user has not seen/rated that movie. The movies_feats matrix contains the features for each of the given movies. Each row represents one of the six movies, the columns represent the five categories. A one indicates that a movie fits within a given genre/category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0asiLTwdJmV"
   },
   "outputs": [],
   "source": [
    "# each row represents a user's rating for the different movies\n",
    "users_movies = tf.constant([\n",
    "                [4,  6,  8,  0, 0, 0],\n",
    "                [0,  0, 10,  0, 8, 3],\n",
    "                [0,  6,  0,  0, 3, 7],\n",
    "                [10, 9,  0,  5, 0, 2]],dtype=tf.float32)\n",
    "\n",
    "# features of the movies one-hot encoded\n",
    "# e.g. columns could represent ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
    "movies_feats = tf.constant([\n",
    "                [1, 1, 0, 0, 1],\n",
    "                [1, 1, 0, 0, 0],\n",
    "                [0, 0, 1, 1, 0],\n",
    "                [1, 0, 1, 1, 0],\n",
    "                [0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 1]],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCW5BtGudJmX"
   },
   "source": [
    "### Computing the user feature matrix\n",
    "\n",
    "We will compute the user feature matrix; that is, a matrix containing each user's embedding in the five-dimensional feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "isMCBMOFdJmY",
    "outputId": "cf7eaa50-95ab-4e8f-916b-27c26d6421dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[10., 10.,  8.,  8.,  4.],\n",
       "       [ 3.,  0., 10., 10., 11.],\n",
       "       [13.,  6.,  0.,  0., 10.],\n",
       "       [26., 19.,  5.,  5., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_feats = tf.matmul(users_movies,movies_feats)\n",
    "users_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ps7XXoYwdJmc"
   },
   "source": [
    "Next we normalize each user feature vector to sum to 1. Normalizing isn't strictly neccesary, but it makes it so that rating magnitudes will be comparable between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "y81EeooodJmc",
    "outputId": "904beb39-0a6f-49e0-971f-5198003e7adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[0.25      , 0.25      , 0.2       , 0.2       , 0.1       ],\n",
       "       [0.0882353 , 0.        , 0.29411766, 0.29411766, 0.32352942],\n",
       "       [0.44827586, 0.20689656, 0.        , 0.        , 0.3448276 ],\n",
       "       [0.3880597 , 0.2835821 , 0.07462686, 0.07462686, 0.17910448]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_feats = users_feats/tf.reduce_sum(users_feats,axis=1,keepdims=True)\n",
    "users_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqOPr51tdJmf"
   },
   "source": [
    "#### Ranking feature relevance for each user\n",
    "\n",
    "We can use the users_feats computed above to represent the relative importance of each movie category for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "PKLqAD3adJmg",
    "outputId": "d535513e-72cd-4120-ef6d-82424efb20d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=int32, numpy=\n",
       "array([[0, 1, 2, 3, 4],\n",
       "       [4, 2, 3, 0, 1],\n",
       "       [0, 4, 1, 2, 3],\n",
       "       [0, 1, 4, 2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_users_features = tf.nn.top_k(users_feats, num_feats)[1]\n",
    "top_users_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "pvUmu7MUdJmj",
    "outputId": "a9e89bb0-330b-4687-866e-0f209910d8c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ryan: ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
      "Danielle: ['Drama', 'Comedy', 'Cartoon', 'Action', 'Sci-Fi']\n",
      "Vijay: ['Action', 'Drama', 'Sci-Fi', 'Comedy', 'Cartoon']\n",
      "Chris: ['Action', 'Sci-Fi', 'Drama', 'Comedy', 'Cartoon']\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_users):\n",
    "    feature_names = [features[int(index)] for index in top_users_features[i]]\n",
    "    print('{}: {}'.format(users[i],feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yne0CyZMdJmn"
   },
   "source": [
    "### Determining movie recommendations. \n",
    "\n",
    "We'll now use the `users_feats` tensor we computed above to determine the movie ratings and recommendations for each user.\n",
    "\n",
    "To compute the projected ratings for each movie, we compute the similarity measure between the user's feature vector and the corresponding movie feature vector.  \n",
    "\n",
    "We will use the dot product as our similarity measure. In essence, this is a weighted movie average for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=float32, numpy=\n",
       "array([[0.6       , 0.5       , 0.4       , 0.65      , 0.1       ,\n",
       "        0.35      ],\n",
       "       [0.4117647 , 0.0882353 , 0.5882353 , 0.67647064, 0.32352942,\n",
       "        0.4117647 ],\n",
       "       [1.        , 0.6551724 , 0.        , 0.44827586, 0.3448276 ,\n",
       "        0.79310346],\n",
       "       [0.8507463 , 0.6716418 , 0.14925373, 0.53731346, 0.17910448,\n",
       "        0.5671642 ]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ratings = tf.matmul(users_feats,tf.transpose(movies_feats))\n",
    "users_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o07wODzddJmq"
   },
   "source": [
    "The computation above finds the similarity measure between each user and each movie in our database. To focus only on the ratings for new movies, we apply a mask to the all_users_ratings matrix.  \n",
    "\n",
    "If a user has already rated a movie, we ignore that rating. This way, we only focus on ratings for previously unseen/unrated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "xUgOnV3AdJmr",
    "outputId": "2672899f-d626-4e33-e730-7d8b051a3954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , 0.65      , 0.1       ,\n",
       "        0.35      ],\n",
       "       [0.4117647 , 0.0882353 , 0.        , 0.67647064, 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.44827586, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.14925373, 0.        , 0.17910448,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ratings_new = tf.where(tf.equal(users_movies, tf.zeros_like(users_movies)),\n",
    "                                  users_ratings,\n",
    "                                  tf.zeros_like(tf.cast(users_movies, tf.float32)))\n",
    "users_ratings_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyNvH46zdJmu"
   },
   "source": [
    "Finally let's grab and print out the top 2 rated movies for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "PdDGgmSpdJmv",
    "outputId": "a921b943-383b-4984-cffd-e0eb5c7ab41e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
       "array([[3, 5],\n",
       "       [3, 0],\n",
       "       [0, 3],\n",
       "       [4, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies = tf.nn.top_k(users_ratings_new, num_recommendations)[1]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "dCB7Dv9_dJmx",
    "outputId": "0d00e5c6-f7bc-4fae-a359-283f2fdb1c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ryan: ['The Incredibles', 'Memento']\n",
      "Danielle: ['The Incredibles', 'Star Wars']\n",
      "Vijay: ['Star Wars', 'The Incredibles']\n",
      "Chris: ['Bleu', 'Shrek']\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_users):\n",
    "    movie_names = [movies[index] for index in top_movies[i]]\n",
    "    print('{}: {}'.format(users[i],movie_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "content_based_by_hand.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
