{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quick Machine Learning Modelling Tutorial with Python and Scikit-Learn\n",
    "\n",
    "This notebook goes through a range of common and useful featues of the Scikit-Learn library.\n",
    "\n",
    "It's long but it's called quick because of how vast the Scikit-Learn library is. Covering everything requires a <a href=\"https://scikit-learn.org/stable/user_guide.html\">full-blown documentation</a>, of which, if you ever get stuck, you should read.\n",
    "\n",
    "## What is Scikit-Learn (sklearn)?\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/index.html\">Scikit-Learn</a>, also referred to as sklearn, is an open-source Python machine learning library.\n",
    "\n",
    "It's built on top on NumPy (Python library for numerical computing) and Matplotlib (Python library for data visualization).\n",
    "\n",
    "<img src=\"F:/zero-to-mastery-ml/images/numpy-6-step-ml-framework-tools-numpy-highlight.png\">\n",
    "\n",
    "## Why Scikit-Learn?\n",
    "\n",
    "Although the field of machine learning is vast, the main goal is finding patterns within data and then using those patterns to make predictions.\n",
    "\n",
    "And there are certain categories which a majority of problems fall into.\n",
    "\n",
    "If you're trying to create a machine learning model to predict whether an email is spam and or not spam, you're working on a classification problem (whether something is something(s) or another).\n",
    "\n",
    "If you're trying to create a machine learning model to predict the price of houses given their characteristics, you're working on a regression problem (predicting a number).\n",
    "\n",
    "Once you know what kind of problem you're working on, there are also similar steps you'll take for each. Steps like splitting the data into different sets, one for your machine learning algorithms to learn on and another to test them on. Choosing a machine learning model and then evaluating whether or not your model has learned anything.\n",
    "\n",
    "Scikit-Learn offers Python implementations for doing all of these kinds of tasks. Saving you having to build them from scratch.\n",
    "\n",
    "## What does this notebook cover?\n",
    "\n",
    "The Scikit-Learn library is very capable. However, learning everything off by heart isn't necessary. Instead, this notebook focuses some of the main use cases of the library.\n",
    "\n",
    "More specifically, we'll cover:\n",
    "\n",
    "<img src=\"F:/CoLab/zero-to-mastery-ml-master/images/sklearn-workflow.png\">\n",
    "\n",
    "1. An end-to-end Scikit-Learn worfklow\n",
    "2. Getting the data ready\n",
    "3. Choosing the right maching learning estimator/aglorithm/model for your problem\n",
    "4. Fitting your chosen machine learning model to data and using it to make a prediction\n",
    "5. Evaluting a machine learning model\n",
    "6. Improving predictions through experimentation (hyperparameter tuning)\n",
    "7. Saving and loading a pretrained model\n",
    "8. Putting it all together in a pipeline\n",
    "\n",
    "<b>Note</b>: all of the steps in this notebook are focused on <b>supervised learning</b> (having data and labels).\n",
    "\n",
    "After going through it, you'll have the base knolwedge of Scikit-Learn you need to keep moving forward.\n",
    "\n",
    "## Where can I get help?\n",
    "\n",
    "If you get stuck or think of something you'd like to do which this notebook doesn't cover, don't fear!\n",
    "\n",
    "The recommended steps you take are:\n",
    "\n",
    "1. <b>Try it</b> - Since Scikit-Learn has been designed with usability in mind, your first step should be to use what you know and try figure out the answer to your own question (getting it wrong is part of the process). If in doubt, run your code.\n",
    "2. <b>Press SHIFT+TAB</b> - See you can the docstring of a function (information on what the function does) by pressing <b>SHIFT + TAB</b> inside it. Doing this is a good habit to develop. It'll improve your research skills and give you a better understanding of the library.\n",
    "3. <b>Search for it</b> - If trying it on your own doesn't work, since someone else has probably tried to do something similar, try searching for your problem. You'll likely end up in 1 of 2 places:\n",
    "\n",
    "- <a herf=\"https://scikit-learn.org/stable/user_guide.html\">Scikit-Learn documentation/user guide</a> - the most extensive resource you'll find for Scikit-Learn information.\n",
    "- <a herf=\"https://stackoverflow.com/\">Stack Overflow</a> - this is the developers Q&A hub, it's full of questions and answers of different problems across a wide range of software development topics and chances are, there's one related to your problem.\n",
    "\n",
    "An example of searching for a Scikit-Learn solution might be:\n",
    "\n",
    "    \"how to tune the hyperparameters of a sklearn model\"\n",
    "\n",
    "Searching this on Google leads to the Scikit-Learn documentation for the GridSearchCV function: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "\n",
    "The next steps here are to read through the documentation, check the examples and see if they line up to the problem you're trying to solve. If they do, <b>rewrite the code</b> to suit your needs, run it, and see what the outcomes are.\n",
    "\n",
    "1. <b>Ask for help - </b> If you've been through the above 3 steps and you're still stuck, you might want to ask your question on <a herf=\"https://www.stackoverflow.com/\">Stack Overflow</a>. Be as specific as possible and provide details on what you've tried.\n",
    "\n",
    "Remember, you don't have to learn all of the functions off by heart to begin with.\n",
    "\n",
    "What's most important is continually asking yourself, \"what am I trying to do with the data?\".\n",
    "\n",
    "Start by answering that question and then practicing finding the code which does it.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. An end-to-end Scikit-Learn workflow\n",
    "\n",
    "Before we get in-depth, let's quickly check out what an end-to-end Scikit-Learn workflow might look like.\n",
    "\n",
    "Once we've seen an end-to-end workflow, we'll dive into each step a little deeper.\n",
    "\n",
    "<b>Note</b>: Since Scikit-Learn is such a vast library, capable of tackling many problems, the workflow we're using is only one example of how you can use it.\n",
    "\n",
    "### Random Forest Classifier Workflow for Classifying Heart Disease\n",
    "\n",
    "#### 1. Get the data ready\n",
    "\n",
    "As an example dataset, we'll import heart-disease.csv. This file contains anonymised patient medical records and whether or not they have heart disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heart_disease = pd.read_csv('F:/zero-to-mastery-ml/heart-disease.csv')\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each row is a different patient and all columns except target are different patient characteristics. target indicates whether the patient has heart disease (target = 1) or not (target = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (all the feature columns)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (the target column)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: target, dtype: int64,\n",
       " 1    165\n",
       " 0    138\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (76, 13), (227,), (76,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose the model and hyperparameters\n",
    "\n",
    "This is often referred to as model or clf (short for classifier) or estimator (as in the Scikit-Learn) documentation.\n",
    "\n",
    "Hyperparameters are like knobs on an oven you can tune to cook your favourite dish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll leave the hyperparameters as default to begin with...\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit the model to the data and use it to make a prediction\n",
    "\n",
    "Fitting the model on the data involves passing it the data and asking it to figure out the patterns.\n",
    "\n",
    "If there are labels (supervised learning), the model tries to work out the relationship between the data and the labels.\n",
    "\n",
    "If there are no labels (unsupervised learning), the model tries to find patterns and group similar samples together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the model to make a prediction\n",
    "\n",
    "The whole point of training a machine learning model is to use it to make some kind of prediction in the future.\n",
    "\n",
    "Once our model instance is trained, you can use the predict() method to predict a target value given a set of features. In other words, use the model, along with some unlabelled data to predict the label.\n",
    "\n",
    "Note, data you predict on has to be in the same shape as data you trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "72    29    1   1       130   204    0        0      202      0      0.0   \n",
       "138   57    1   0       110   201    0        1      126      1      1.5   \n",
       "148   44    1   2       120   226    0        1      169      0      0.0   \n",
       "145   70    1   1       156   245    0        0      143      0      0.0   \n",
       "140   51    0   2       120   295    0        0      157      0      0.6   \n",
       "\n",
       "     slope  ca  thal  \n",
       "72       2   0     2  \n",
       "138      1   0     1  \n",
       "148      2   0     2  \n",
       "145      2   0     2  \n",
       "140      2   0     2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to predict a label, data has to be in the same shape as X_train\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make a prediction on the test data (further evaluation)\n",
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model\n",
    "\n",
    "Now we've made some predictions, we can start to use some more Scikit-Learn methods to figure out how good our model is.\n",
    "\n",
    "Each model or estimator has a built-in score method. This method compares how well the model was able to learn the patterns between the features and labels. In other words, it returns how accurate your model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881578947368421"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a number of other evaluation methods we can use for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        31\n",
      "           1       0.88      0.93      0.90        45\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.87      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  6],\n",
       "       [ 3, 42]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881578947368421"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Experiment to improve\n",
    "\n",
    "The first model you build is often referred to as a baseline.\n",
    "\n",
    "Once you've got a baseline model, like we have here, it's important to remember, this is often not the final model you'll use.\n",
    "\n",
    "The next step in the workflow is to try and improve upon your baseline model.\n",
    "\n",
    "And to do this, there's two ways to look at it. From a model perspective and from a data perspective.\n",
    "\n",
    "From a model perspective this may involve things such as using a more complex model or tuning your models hyperparameters.\n",
    "\n",
    "From a data perspective, this may involve collecting more data or better quality data so your existing model has more of a chance to learn the patterns within.\n",
    "\n",
    "If you're already working on an existing dataset, it's often easier try a series of model perspective experiments first and then turn to data perspective experiments if you aren't getting the results you're looking for.\n",
    "\n",
    "One thing you should be aware of is if you're tuning a models hyperparameters in a series of experiments, your reuslts should always be cross-validated. Cross-validation is a way of making sure the results you're getting are consistent across your training and test datasets (because it uses multiple versions of training and test sets) rather than just luck because of the order the original training and test sets were created.\n",
    "\n",
    "- Try different hyperparameters\n",
    "- All different parameters should be cross-validated\n",
    "\n",
    " - <b>Note</b>: Beware of cross-validation for time series problems\n",
    "\n",
    "Different models you use will have different hyperparameters you can tune. For the case of our model, the RandomForestClassifier(), we'll start trying different values for n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 90.78947368421053%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 93.42105263157895%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 89.47368421052632%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 88.1578947368421%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 88.1578947368421%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 92.10526315789474%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try different numbers of estimators (trees)... (no cross-validation)\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "Cross-validation score: 78.53551912568305%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 92.10526315789474%\n",
      "Cross-validation score: 79.84699453551912%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "Cross-validation score: 80.50819672131148%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 88.1578947368421%\n",
      "Cross-validation score: 82.15300546448088%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 89.47368421052632%\n",
      "Cross-validation score: 81.1639344262295%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "Cross-validation score: 83.47540983606557%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "Cross-validation score: 81.83060109289617%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "Cross-validation score: 82.81420765027322%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 86.8421052631579%\n",
      "Cross-validation score: 82.81967213114754%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# With cross-validation\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100}%\")\n",
    "    print(f\"Cross-validation score: {np.mean(cross_val_score(model, X, y, cv=5)) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Another way to do it with GridSearchCV...\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameters to search over\n",
    "param_grid = {'n_estimators': [i for i in range(10, 100, 10)]}\n",
    "\n",
    "# Setup the grid search\n",
    "grid = GridSearchCV(RandomForestClassifier(),\n",
    "                    param_grid,\n",
    "                    cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Find the best parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to be the best estimator\n",
    "clf = grid.best_estimator_\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881578947368421"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model scores\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save a model for someone else to use\n",
    "\n",
    "When you've done a few experiments and you're happy with how your model is doing, you'll likely want someone else to be able to use it.\n",
    "\n",
    "This may come in the form of a teammate or colleague trying to replicate and validate your results or through a customer using your model as part of a service or application you offer.\n",
    "\n",
    "Saving a model also allows you to reuse it later without having to go through retraining it. Which is helpful, especially when your training times start to increase.\n",
    "\n",
    "You can save a scikit-learn model using Python's in-built pickle module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(model, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a saved model and make a prediction\n",
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the data ready\n",
    "\n",
    "Data doesn't always come ready to use with a Scikit-Learn machine learning model.\n",
    "\n",
    "Three of the main steps you'll often have to take are:\n",
    "\n",
    "- Splitting the data into features (usually X) and labels (usually y)\n",
    "- Filling (also called imputing) or disregarding missing values\n",
    "- Converting non-numerical values to numerical values (also call feature encoding)\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into X & y\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop('target', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, Length: 303, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2) # you can change the test size\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% of data is being used for the test set \n",
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Make sure it's all numerical\n",
    "\n",
    "We want to turn the \"Make\" and \"Colour\" columns into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820</td>\n",
       "      <td>4</td>\n",
       "      <td>32042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>155144</td>\n",
       "      <td>3</td>\n",
       "      <td>5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604</td>\n",
       "      <td>4</td>\n",
       "      <td>31570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883</td>\n",
       "      <td>4</td>\n",
       "      <td>4001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360</td>\n",
       "      <td>4</td>\n",
       "      <td>12732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors  Price\n",
       "0     Honda  White          35431      4  15323\n",
       "1       BMW   Blue         192714      5  19943\n",
       "2     Honda  White          84714      4  28343\n",
       "3    Toyota  White         154365      4  13434\n",
       "4    Nissan   Blue         181577      3  14043\n",
       "..      ...    ...            ...    ...    ...\n",
       "995  Toyota  Black          35820      4  32042\n",
       "996  Nissan  White         155144      3   5716\n",
       "997  Nissan   Blue          66604      4  31570\n",
       "998   Honda  White         215883      4   4001\n",
       "999  Toyota   Blue         248360      4  12732\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import car-sales-extended.csv\n",
    "car_sales = pd.read_csv(\"F:/zero-to-mastery-ml/car-sales-extended.csv\")\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y and train/test\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and build a model on our car_sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 3.5431e+04])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             Honda\n",
       "Colour           White\n",
       "Odometer (KM)    35431\n",
       "Doors                4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way... using pandas and pd.get_dummies()\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0        4         0           1            0            0             0   \n",
       "1        5         1           0            0            0             0   \n",
       "2        4         0           1            0            0             0   \n",
       "3        4         0           0            0            1             0   \n",
       "4        3         0           0            1            0             0   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "995      4         0           0            0            1             1   \n",
       "996      3         0           0            1            0             0   \n",
       "997      4         0           0            1            0             0   \n",
       "998      4         0           1            0            0             0   \n",
       "999      4         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0              0             0           0             1  \n",
       "1              1             0           0             0  \n",
       "2              0             0           0             1  \n",
       "3              0             0           0             1  \n",
       "4              1             0           0             0  \n",
       "..           ...           ...         ...           ...  \n",
       "995            0             0           0             0  \n",
       "996            0             0           0             1  \n",
       "997            1             0           0             0  \n",
       "998            0             0           0             1  \n",
       "999            1             0           0             0  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "      <th>Doors_3</th>\n",
       "      <th>Doors_4</th>\n",
       "      <th>Doors_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0           0           1            0            0             0   \n",
       "1           1           0            0            0             0   \n",
       "2           0           1            0            0             0   \n",
       "3           0           0            0            1             0   \n",
       "4           0           0            1            0             0   \n",
       "..        ...         ...          ...          ...           ...   \n",
       "995         0           0            0            1             1   \n",
       "996         0           0            1            0             0   \n",
       "997         0           0            1            0             0   \n",
       "998         0           1            0            0             0   \n",
       "999         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  Doors_3  Doors_4  \\\n",
       "0              0             0           0             1        0        1   \n",
       "1              1             0           0             0        0        0   \n",
       "2              0             0           0             1        0        1   \n",
       "3              0             0           0             1        0        1   \n",
       "4              1             0           0             0        1        0   \n",
       "..           ...           ...         ...           ...      ...      ...   \n",
       "995            0             0           0             0        0        1   \n",
       "996            0             0           0             1        1        0   \n",
       "997            1             0           0             0        0        1   \n",
       "998            0             0           0             1        0        1   \n",
       "999            1             0           0             0        0        1   \n",
       "\n",
       "     Doors_5  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "995        0  \n",
       "996        0  \n",
       "997        0  \n",
       "998        0  \n",
       "999        0  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Have to convert doors to object for dummies to work on it...\n",
    "car_sales[\"Doors\"] = car_sales[\"Doors\"].astype(object)\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toyota    398\n",
       "Honda     304\n",
       "Nissan    198\n",
       "BMW       100\n",
       "Name: Make, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The categorical categories are now either 1 or 0...\n",
    "X[\"Make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=90,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What if there were missing values?\n",
    "\n",
    "Many machine learning models don't work well when there are missing values in the data.\n",
    "\n",
    "There are two main options when dealing with missing values.\n",
    "\n",
    "1. Fill them with some given value. For example, you might fill missing values of a numerical column with the mean of all the other values. The practice of filling missing values is often referred to as imputation.\n",
    "2. Remove them. If a row has missing values, you may opt to remove them completely from your sample completely. However, this potentially results in using less data to build your model.\n",
    "\n",
    "<b>Note</b>: Dealing with missing values is a problem to problem issue. And there's often no best way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import car sales dataframe with missing values\n",
    "car_sales_missing = pd.read_csv(\"F:/zero-to-mastery-ml/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d551dd97a0c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                  categorical_features)],\n\u001b[0;32m     10\u001b[0m                                  remainder=\"passthrough\")\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtransformed_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_sales_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtransformed_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    455\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m    456\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[1;32m--> 457\u001b[1;33m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[0;32m    458\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \"\"\"\n\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \"\"\"\n\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[1;32m---> 61\u001b[1;33m                              force_all_finite=needs_validation)\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Fill missing data with pandas\n",
    "\n",
    "What we'll do is fill the rows where categorical values are missing with \"missing\", the numerical features with the mean or 4 for the doors. And drop the rows where the Price is missing.\n",
    "\n",
    "We could fill Price with the mean, however, since it's the target variable, we don't want to be introducing too many fake labels.\n",
    "\n",
    "<b>Note</b>: The practice of filling missing data is called <b>imputation</b>. And it's important to remember there's no perfect way to fill missing data. The methods we're using are only one of many. The techniques you use will depend heavily on your dataset. A good place to look would be searching for \"data imputation techniques\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our dataframe\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price labels\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our dataframe\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've removed the rows with missing Price values, now there's less data but there's no more missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's one-hot encode the categorical columns (copied from above)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 3.5431e+04,\n",
       "       1.5323e+04])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Filling missing data and transforming categorical data with Scikit-Learn\n",
    "Now we've filled the missing columns using pandas functions, you might be thinking, \"Why pandas? I thought this was a Scikit-Learn introduction?\".\n",
    "\n",
    "Not to worry, scikit-learn provides another method called SimpleImputer() which allows us to do a similar thing.\n",
    "\n",
    "SimpleImputer() transforms data by filling missing values with a given strategy.\n",
    "\n",
    "And we can use it to fill the missing values in our DataFrame as above.\n",
    "\n",
    "At the moment, our dataframe has no mising values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reimport it so it has missing values and we can fill them with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimport the DataFrame\n",
    "car_sales_missing = pd.read_csv(\"F:/zero-to-mastery-ml/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the rows with missing in the \"Price\" column\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "# Split data into train and test\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: We split data into train & test to perform filling missing values on them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with 'missing' & numerical with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different column features\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "numerical_feature = [\"Odometer (KM)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: We use fit_transform() on the training data and transform() on the testing data. In essence, we learn the patterns in the training set and transform it via imputation (fit, then transform). Then we take those same patterns and fill the test set (transform only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 71934.0],\n",
       "       ['Toyota', 'Red', 4.0, 162665.0],\n",
       "       ['Honda', 'White', 4.0, 42844.0],\n",
       "       ...,\n",
       "       ['Toyota', 'White', 4.0, 196225.0],\n",
       "       ['Honda', 'Blue', 4.0, 133117.0],\n",
       "       ['Honda', 'missing', 4.0, 150582.0]], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, categorical_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, numerical_feature)])\n",
    "\n",
    "# Fill train and test values separately\n",
    "filled_X_train = imputer.fit_transform(X_train)\n",
    "filled_X_test = imputer.transform(X_test)\n",
    "\n",
    "# Check filled X_train\n",
    "filled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our transformed data array's back into DataFrame's\n",
    "car_sales_filled_train = pd.DataFrame(filled_X_train, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "# Check missing data in training set\n",
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see the original... still missing values\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 7.19340e+04],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.62665e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 4.28440e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.96225e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.33117e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.50582e+05]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's one hot encode the features with the same code as before \n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train)\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test)\n",
    "\n",
    "# Check transformed and filled X_train\n",
    "transformed_X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21229043336119102"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we've transformed X, let's see if we can fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Make sure to use transformed (filled and one-hot encoded X data)\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this looks confusing, don't worry, we've covered a lot of ground very quickly. And we'll revisit these strategies in a future section in way which makes a lot more sense.\n",
    "\n",
    "For now, the key takeaways to remember are:\n",
    "\n",
    "- Most datasets you come across won't be in a form ready to immediately start using them with machine learning models. And some may take more preparation than others to get ready to use.\n",
    "- For most machine learning models, your data has to be numerical. This will involve converting whatever you're working with into numbers. This process is often referred to as <b>feature engineering</b> or <b>feature encoding</b>.\n",
    "- Some machine learning models aren't compatible with missing data. The process of filling missing data is referred to as <b>data imputation</b>.\n",
    "\n",
    "## 2. Choosing the right estimator/algorithm for your problem\n",
    "\n",
    "Once you've got your data ready, the next step is to choose an appropriate machine learning algorithm or model to find patterns in your data.\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "- Sklearn refers to machine learning models and algorithms as estimators.\n",
    "- Classification problem - predicting a category (heart disease or not).\n",
    "  - Sometimes you'll see clf (short for classifier) used as a classification estimator instance's variable name.\n",
    "- Regression problem - predicting a number (selling price of a car).\n",
    "- Unsupervised problem - clustering (grouping unlabelled samples with other similar unlabelled samples).\n",
    "\n",
    "If you know what kind of problem you're working with, one of the next places you should look at is the <a href=\"https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\">Scikit-Learn algorithm cheatsheet</a>.\n",
    "\n",
    "This cheatsheet gives you a bit of an insight into the algorithm you might want to use for the problem you're working on.\n",
    "\n",
    "It's important to remember, you don't have to explicitly know what each algorithm is doing on the inside to start using them. If you do start to apply different algorithms but they don't seem to be working, that's when you'd start to look deeper into each one.\n",
    "\n",
    "Let's check out the cheatsheet and follow it for some of the problems we're working on.\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map.png\" width=700/>\n",
    "\n",
    "You can see it's split into four main categories. Regression, classification, clustering and dimensionality reduction. Each has their own different purpose but the Scikit-Learn team has designed the library so the workflows for each are relatively similar.\n",
    "\n",
    "Let's start with a regression problem. We'll use the <a href=\"https://scikit-learn.org/stable/datasets/index.html#boston-dataset\">Boston housing dataset</a> built into Scikit-Learn's datasets module.\n",
    "\n",
    "### 2.1 Picking a machine learning model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston; # imports as dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's in a dictionary, let's turn it into a DataFrame so we can inspect it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "boston_df[\"target\"] = pd.Series(boston[\"target\"])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples?\n",
    "len(boston_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, our goal here is to use the feature columns, such as CRIM, which is the per capita crime rate by town, AGE, the proportion of owner-occupied units built prior to 1940 and more to predict the target column. Where the target column is the median house prices.\n",
    "\n",
    "In essence, each row is a different town in Boston (the data) and we're trying to build a model to predict the median house price (the label) of a town given a series of attributes about the town.\n",
    "\n",
    "Since we have data and labels, this is a supervised learning problem. And since we're trying to predict a number, it's a regression problem.\n",
    "\n",
    "Knowing these two things, how do they line up on the Scikit-Learn machine learning algorithm cheat-sheet?\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-boston-housing-ridge.png\" width=700/>\n",
    "\n",
    "Following the map through, knowing what we know, it suggests we try <a href=\"https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\">RidgeRegression</a>. Let's chek it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168522"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Ridge model class from the linear_model module\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if RidgeRegression didn't work? Or what if we wanted to improve our results?\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-boston-housing-ensemble.png\" width=700/>\n",
    "\n",
    "Following the diagram, the next step would be to try <a href=\"https://scikit-learn.org/stable/modules/ensemble.html\">EnsembleRegressors</a>. Ensemble is another word for multiple models put together to make a decision.\n",
    "\n",
    "One of the most common and useful ensemble methods is the <a href=\"https://scikit-learn.org/stable/modules/ensemble.html#forest\">Random Forest</a>. Known for its fast training and prediction times and adaptibility to different problems.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, <a href=\"https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\">An Implementation and Explanation of the Random Forest in Python</a> by Will Koehrsen is a great read.\n",
    "\n",
    "Since we're working with regression, we'll use Scikit-Learn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">RandomForestRegressor</a>.\n",
    "\n",
    "We can use the exact same workflow as above. Except for changing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, we get a boost in score on the test set of almost 0.2 with a change of model.\n",
    "\n",
    "At first, the diagram can seem confusing. But once you get a little practice applying different models to different problems, you'll start to pick up which sorts of algorithms do better with different types of data.\n",
    "\n",
    "### 2.2 Picking a machine learning model for a classification problem\n",
    "\n",
    "Now, let's check out the choosing process for a classification problem.\n",
    "\n",
    "Say you were trying to predict whether or not a patient had heart disease based on their medical records.\n",
    "\n",
    "The dataset in ../data/heart-disease.csv contains data for just that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"F:/zero-to-mastery-ml/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples are there?\n",
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Boston housing dataset, here we want to use all of the available data to predict the target column (1 for if a patient has heart disease and 0 for if they don't).\n",
    "\n",
    "So what do we know?\n",
    "\n",
    "We've got 303 samples (1 row = 1 sample) and we're trying to predict whether or not a patient has heart disease.\n",
    "\n",
    "Because we're trying to predict whether each sample is one thing or another, we've got a classification problem.\n",
    "\n",
    "Let's see how it lines up with our <a href=\"https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\">Scikit-Learn algorithm cheat-sheet</a>.\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-heart-disease-linear-svc.png\" width=700/>\n",
    "\n",
    "Following the cheat-sheet we end up at <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\">LinearSVC</a> which stands for Linear Support Vector Classifier. Let's try it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4918032786885246"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "clf = LinearSVC(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight out of the box (with no tuning or improvements) the model scores 47% accuracy, which with 2 classes (heart disease or not) is as good as guessing.\n",
    "\n",
    "With this result, we'll go back to our diagram and see what our options are.\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-heart-disease-ensemble.png\" width=700/>\n",
    "\n",
    "Following the path (and skipping a few, don't worry, we'll get to this) we come up to <a href=\"https://scikit-learn.org/stable/modules/ensemble.html\">EnsembleMethods</a> again. Except this time, we'll be looking at ensemble classifiers instead of regressors.\n",
    "\n",
    "Remember our <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">RandomForestRegressor</a> from above? We'll it has a dance partner, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">RandomForestClassifier</a> which is an ensemble based machine model learning model for classification. You might be able to guess what we can use it for.\n",
    "\n",
    "Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the RandomForestClassifier we get almost double the score of LinearSVC.\n",
    "\n",
    "One thing to remember, is both models are yet to receive any hyperparameter tuning. Hyperparameter tuning is fancy term for adjusting some settings on a model to try and make it better. It usually happens once you've found a decent baseline result you'd like to improve upon.\n",
    "\n",
    "In this case, we'd probably take the RandomForestClassifier and try and improve it with hyperparameter tuning (which we'll see later on).\n",
    "\n",
    "## What about the other models?\n",
    "\n",
    "Looking at the cheat-sheet and the examples above, you may have noticed we've skipped a few.\n",
    "\n",
    "Why?\n",
    "\n",
    "The first reason is time. Covering every single one would take a fair bit longer than what we've done here. And the second one is the effectiveness of ensemble methods.\n",
    "\n",
    "A little tidbit for modelling in machine learning is:\n",
    "\n",
    "- If you have structured data (tables or dataframes), use ensemble methods, such as, a Random Forest.\n",
    "- If you have unstructured data (text, images, audio, things not in tables), use deep learning or transfer learning.\n",
    "\n",
    "For this notebook, we're focused on structured data, which is why the Random Forest has been our model of choice.\n",
    "\n",
    "If you'd like to learn more about the Random Forest and why it's the war horse of machine learning, check out these resources:\n",
    "\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Random_forest\">Random Forest Wikipedia</a>\n",
    "- <a href=\"http://blog.yhat.com/posts/random-forests-in-python.html\">Random Forests in Python</a> by yhat\n",
    "- <a href=\"https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\">An Implementation and Explanation of the Random Forest in Python</a> by Will Koehrsen\n",
    "\n",
    "#### Experiment until something works\n",
    "\n",
    "The beautiful thing is, the way the Scikit-Learn API is designed, once you know the way with one model, using another is much the same.\n",
    "\n",
    "And since a big part of being a machine learning engineer or data scientist is experimenting, you might want to try out some of the other models on the cheat-sheet and see how you go. The more you can reduce the time between experiments, the better.\n",
    "\n",
    "### 3. Fit the model to data and using it to make predictions\n",
    "\n",
    "Now you've chosen a model, the next step is to have it learn from the data so it can be used for predictions in the future.\n",
    "\n",
    "If you've followed through, you've seen a few examples of this already.\n",
    "\n",
    "#### 3.1 Fitting a model to data\n",
    "\n",
    "In Scikit-Learn, the process of having a machine learning model learn patterns from a dataset involves calling the fit() method and passing it data, such as, fit(X, y).\n",
    "\n",
    "Where X is a feature array and y is a target array.\n",
    "\n",
    "Other names for X include:\n",
    "\n",
    "- Data\n",
    "- Feature variables\n",
    "- Features\n",
    "\n",
    "Other names for y include:\n",
    "\n",
    "- Labels\n",
    "- Target variable\n",
    "\n",
    "For supervised learning there is usually an X and y. For unsupervised learning, there's no y (no labels).\n",
    "\n",
    "Let's revisit the example of using patient data (X) to predict whether or not they have heart disease (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "Calling the fit() method will cause the machine learning algorithm to attempt to find patterns between X and y. Or if there's no y, it'll only find the patterns within X.\n",
    "\n",
    "Let's see X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing X and y to fit() will cause the model to go through all of the examples in X (data) and see what their corresponding y (label) is.\n",
    "\n",
    "How the model does this is different depending on the model you use.\n",
    "\n",
    "Explaining the details of each would take an entire textbook.\n",
    "\n",
    "For now, you could imagine it similar to how you would figure out patterns if you had enough time.\n",
    "\n",
    "You'd look at the feature variables, X, the age, sex, chol (cholesterol) and see what different values led to the labels, y, 1 for heart disease, 0 for not heart disease.\n",
    "\n",
    "This concept, regardless of the problem, is similar throughout all of machine learning.\n",
    "\n",
    "#### During training (finding patterns in data):\n",
    "\n",
    "A machine learning algorithm looks at a dataset, finds patterns, tries to use those patterns to predict something and corrects itself as best it can with the available data and labels. It stores these patterns for later use.\n",
    "\n",
    "#### During testing or in production (using learned patterns):\n",
    "\n",
    "A machine learning algorithm uses the patterns its previously learned in a dataset to make a prediction on some unseen data.\n",
    "\n",
    "### 3.2 Making predictions using a machine learning model\n",
    "Now we've got a trained model, one which has hoepfully learned patterns in the data, you'll want to use it to make predictions.\n",
    "\n",
    "Scikit-Learn enables this in several ways. Two of the most common and useful are <a href=\"https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/multiclass.py#L299\">predict()</a> and <a href=\"https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_logistic.py#L1617\">predict_proba()</a>.\n",
    "\n",
    "Let's see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data in the form of X, the predict() function returns labels in the form of y.\n",
    "\n",
    "It's standard practice to save these predictions to a variable named something like y_preds for later comparison to y_test or y_true (usually same as y_test just another name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predictions to truth\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of doing this is with Scikit-Learn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">accuracy_score()</a> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: For the predict() function to work, it must be passed X (data) in the same format the model was trained on. Anything different and it will return an error.\n",
    "\n",
    "predict_proba() returns the probabilities of a classification label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return probabilities rather than labels\n",
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return labels\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba() returns an array of five arrays each containing two values.\n",
    "\n",
    "Each number is the probability of a label given a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find prediction probabilities for 1 sample\n",
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output means the sample X_test[:1], the model is predicting label 0 (index 0) with a probability score of 0.9.\n",
    "\n",
    "Because the score is over 0.5, when using predict(), a label of 0 is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the label for 1 sample\n",
    "clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does 0.5 come from?\n",
    "\n",
    "Because our problem is a binary classification task (heart disease or not heart disease), predicting a label with 0.5 probability every time would be the same as a coin toss (guessing). Therefore, once the prediction probability of a sample passes 0.5, for a certain label, it's assigned that label.\n",
    "\n",
    "predict() can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1226372549019623"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've seen how to get a model how to find patterns in data using the fit() function and make predictions using what its learned using the predict() and predict_proba() functions, it's time to evaluate those predictions.\n",
    "\n",
    "### 4. Evaluating a model\n",
    "Once you've trained a model, you'll want a way to measure how trustworthy its predictions are.\n",
    "\n",
    "Scikit-Learn implements 3 different methods of evaluating models.\n",
    "\n",
    "1. The score() method. Calling score() on a model instance will return a metric assosciated with the type of model you're using. The metric depends on which model you're using.\n",
    "2. The scoring parameter. This parameter can be passed to methods such as cross_val_score() or GridSearchCV() to tell Scikit-Learn to use a specific type of scoring metric.\n",
    "3. Problem-specific metric functions. Similar to how the scoring parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "The scoring function you use will also depend on the problem you're working on.\n",
    "\n",
    "Classification problems have different evaluation metrics and scoring functions to regression problems.\n",
    "\n",
    "Let's look at some examples.\n",
    "\n",
    "#### 4.1 General model evaluation with score()\n",
    "If we bring down the code from our previous classification problem (building a classifier to predict whether or not someone has heart disease based on their medical records).\n",
    "\n",
    "We can see the score() method come into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been fit on the training data (X_train, y_train), we can call the score() method on it and evaluate our model on the test data, data the model has never seen before (X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because clf is an instance of RandomForestClassifier, the score() method uses mean accuracy as its score method.\n",
    "\n",
    "You can find this by pressing <b>SHIFT + TAB</b> within the brackets of score() when called on a model instance.\n",
    "\n",
    "Behind the scenes, score() makes predictions on X_test using the trained model and then compares those predictions to the actual labels y_test.\n",
    "\n",
    "A model which predicts everything 100% correct would receive a score of 1.0 (or 100%).\n",
    "\n",
    "Our model doesn't get everything correct, but at 85% (0.85 * 100), it's still far better than guessing.\n",
    "\n",
    "Let's do the same but with the regression code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the consistent design of the Scikit-Learn library, we can call the same score() method on model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, model is an instance of RandomForestRegressor. And since it's a regression model, the default metric built into score() is the coefficient of determination or R^2 (pronounced R-sqaured).\n",
    "\n",
    "Remember, you can find this by pressing <b>SHIFT + TAB</b> within the brackets of score() when called on a model instance.\n",
    "\n",
    "The best possible value here is 1.0, this means the model predicts the target regression values exactly.\n",
    "\n",
    "Calling the score() method on any model instance and passing it test data is a good quick way to see how your model is going.\n",
    "\n",
    "However, when you get further into a problem, it's likely you'll want to start using more powerful metrics to evaluate your models performance.\n",
    "\n",
    "### 4.2 Evaluating your models using the scoring parameter\n",
    "\n",
    "The next step up from using score() is to use a custom scoring parameter with <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\">cross_val_score()</a> or <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">GridSearchCV</a>.\n",
    "\n",
    "As you may have guessed, the scoring parameter you set will be different depending on the problem you're working on.\n",
    "\n",
    "We'll see some specific examples of different parameters in a moment but first let's check out cross_val_score().\n",
    "\n",
    "To do so, we'll copy the heart disease classification code from above and then add another line at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score from the model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross_val_score() is slightly different to score(). Let's see a code example first and then we'll go through the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using score()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.81967213, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score()\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "The first difference you might notice is cross_val_score() returns an array where as score() only returns a single number.\n",
    "\n",
    "cross_val_score() returns an array because of a parameter called cv, which stands for cross-validation.\n",
    "\n",
    "When cv isn't set, cross_val_score() will return an array of 3 numbers by default (or 5 by default if you're using Scikit-Learn version 0.22+).\n",
    "\n",
    "Remember, you can see the parameters of a function using <b>SHIFT + TAB</b> from within the brackets.\n",
    "\n",
    "But wait, you might be thinking, what even is cross-validation?\n",
    "\n",
    "A visual might be able to help.\n",
    "\n",
    "<img src='../images/sklearn-cross-validation.png' width=600/>\n",
    "\n",
    "We've dealt with Figure 1.0 before using score(X_test, y_test). But looking deeper into this, if a model is trained using the training data or 80% of samples, this means 20% of samples aren't used for the model to learn anything.\n",
    "\n",
    "This also means depending on what 80% is used to train on and what 20% is used to evaluate the model, it may achieve a score which doesn't reflect the entire dataset. For example, if a lot of easy examples are in the 80% training data, when it comes to test on the 20%, your model may perform poorly. The same goes for the reverse.\n",
    "\n",
    "Figure 2.0 shows 5-fold cross-validation, a method which tries to provide a solution to:\n",
    "\n",
    "- Not training on all the data\n",
    "- Avoiding getting lucky scores on single splits of the data\n",
    "\n",
    "Instead of training only on 1 training split and evaluating on 1 testing split, 5-fold cross-validation does it 5 times. On a different split each time, returning a score for each.\n",
    "\n",
    "Why 5-fold?\n",
    "\n",
    "The actual name of this setup K-fold cross-validation. Where K is an abitrary number. We've used 5 because it looks nice visually, and will be the default in Scikit-Learn from version 0.22 onwards.\n",
    "\n",
    "Figure 2.0 is what happens when we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83606557, 0.8852459 , 0.7704918 , 0.8       , 0.8       ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-fold cross-validation\n",
    "cross_val_score(clf, X, y, cv=5) # cv is equivalent to K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set cv=5 (5-fold cross-validation), we get back 5 different scores instead of 1.\n",
    "\n",
    "Taking the mean of this array gives us a more in-depth idea of how our model is performing by converting the 5 scores into one.\n",
    "\n",
    "Notice, the average cross_val_score() is slightly lower than single value returned by score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8248087431693989)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# Take mean of 5-fold cross-validation\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if you were asked to report the accuracy of your model, even though it's lower, you'd prefer the cross-validated metric over the non-cross-validated metric.\n",
    "\n",
    "Wait?\n",
    "\n",
    "We haven't used the scoring parameter at all.\n",
    "\n",
    "By default, it's set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78688525, 0.86885246, 0.80327869, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5, scoring=None) # default scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scoring is set to None (by default), it uses the same metric as score() for whatever model is passed to cross_val_score().\n",
    "\n",
    "In this case, our model is clf which is an instance of RandomForestClassifier which uses mean accuracy as the default score() metric.\n",
    "\n",
    "You can change the evaluation score cross_val_score() uses by changing the scoring parameter.\n",
    "\n",
    "And as you might have guessed, different problems call for different evaluation scores.\n",
    "\n",
    "The <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\">Scikit-Learn documentation</a> outlines a vast range of evaluation metrics for different problems but let's have a look at a few.\n",
    "\n",
    "### 4.2.1 Classification model evaluation metrics\n",
    "Four of the main evaluation metrics/methods you'll come across for classification models are:\n",
    "\n",
    "- Accuracy\n",
    "- Area under ROC curve\n",
    "- Confusion matrix\n",
    "- Classification report\n",
    "\n",
    "Let's have a look at each of these. We'll bring down the classification code from above to go through some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cross_val_score from the model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "Accuracy is the default metric for the score() function within each of Scikit-Learn's classifier models. And it's probably the metric you'll see most often used for classification problems.\n",
    "\n",
    "However, we'll see in a second how it may not always be the best metric to use.\n",
    "\n",
    "Scikit-Learn returns accuracy as a decimal but you can easily convert it to a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Accuracy: 85.25%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy as percentage\n",
    "print(f\"Heart Disease Classifier Accuracy: {clf.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "If this one sounds like a mouthful, its because reading the full name is.\n",
    "\n",
    "It's usually referred to as AUC for Area Under Curve and the curve they're talking about is the Receiver Operating Characteristic or ROC for short.\n",
    "\n",
    "So if hear someone talking about AUC or ROC, they're probably talking about what follows.\n",
    "\n",
    "ROC curves are a comparison of true postive rate (tpr) versus false positive rate (fpr).\n",
    "\n",
    "For clarity:\n",
    "\n",
    "- True positive = model predicts 1 when truth is 1\n",
    "- False positive = model predicts 1 when truth is 0\n",
    "- True negative = model predicts 0 when truth is 0\n",
    "- False negative = model predicts 0 when truth is 1\n",
    "\n",
    "Now we know this, let's see one. Scikit-Learn lets you calculate the information required for a ROC curve using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve\">roc_curve</a> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.06896552,\n",
       "       0.06896552, 0.10344828, 0.13793103, 0.13793103, 0.17241379,\n",
       "       0.17241379, 0.27586207, 0.4137931 , 0.48275862, 0.55172414,\n",
       "       0.65517241, 0.72413793, 0.72413793, 0.82758621, 1.        ])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Keep the probabilites of the positive class only\n",
    "y_probs = y_probs[:, 1]\n",
    "\n",
    "# Calculate fpr, tpr and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Check the false positive rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these on their own doesn't make much sense. It's much easier to see their value visually.\n",
    "\n",
    "Since Scikit-Learn doesn't have a built-in function to plot a ROC curve, quite often, you'll find a function (or write your own) like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positve rate (fpr) and \n",
    "    true postive rate (tpr) of a classifier.\n",
    "    \"\"\"\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Guessing')\n",
    "    # Customize the plot\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot for the first time, it might seem a bit confusing.\n",
    "\n",
    "The main thing to take away here is our model is doing far better than guessing.\n",
    "\n",
    "A metric you can use to quantify the ROC curve in a single number is AUC (Area Under Curve). Scikit-Learn implements a function to caculate this called <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\">roc_auc_score()</a>.\n",
    "\n",
    "The maximum ROC AUC score you can achieve is 1.0 and generally, the closer to 1.0, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304956896551724"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most ideal position for a ROC curve to run along the top left corner of the plot.\n",
    "\n",
    "This would mean the model predicts only true positives and no false positives. And would result in a ROC AUC score of 1.0.\n",
    "\n",
    "You can see this by creating a ROC curve using only the y_test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot perfect ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perfect ROC AUC score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, a perfect ROC curve is unlikely.\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "The next way to evaluate a classification model is by using a <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">confusion matrix</a>.\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict. In essence, giving you an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  5],\n",
       "       [ 4, 28]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is probably easier visualized.\n",
    "\n",
    "One way to do it is with pd.crosstab()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Label   0   1\n",
       "Actual Label           \n",
       "0                24   5\n",
       "1                 4  28"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, \n",
    "            y_preds, \n",
    "            rownames=[\"Actual Label\"], \n",
    "            colnames=[\"Predicted Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more visual way is with Seaborn's heatmap() plot.\n",
    "\n",
    "If you've never heard of Seaborn, it's a library which is built on top of Matplotlib. It contains a bunch of helpful plotting functions.\n",
    "\n",
    "And if you haven't got Seaborn installed, you can install it into the current environment using:\n",
    "\n",
    "#### Install Seaborn in the current Jupyter Kernel/Conda environment\n",
    "import sys\n",
    "\n",
    "!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a confusion matrix with Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using Seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh.. that plot isn't offering much. Let's add some commucation and functionise it.\n",
    "\n",
    "<b>Note</b>: In the original notebook, the function below had the \"True label\" as the x-axis label and the \"Predicted label\" as the y-axis label. But due to the way confusion_matrix() outputs values, these should be swapped around. The code below has been corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOQAAADfCAYAAADm6n/jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdOUlEQVR4nO3deVxU9f4/8NcwA6KMILjLJiAECipKklEJKnAxDUVZUtBEQ9QQruKCaVS/0jTSS7l8ySXATBEXRMQyXPgqaoZfrqi4YOwooDIqA8gIc35/eJnuNGAzMsM5wPv5ePQH53zm8DoTL8+cM2fhMQzDgBDCCVpsByCE/IkKSQiHUCEJ4RAqJCEcQoUkhEMEbAfQlPqDX7AdodMY9EE82xE6FZH4bqvzaAtJCIdQIQnhECokIRxChSSEQ6iQhHAIFZIQDqFCEsIhVEhCOIQKSQiHUCEJ4RAqJCEcQoUkhEOokIRwCBWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUISwiFUSEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHAIFZIQDqFCEsIhVEhCOKTTPrCVKy7k38OOM9dw894j8Hg8DDftg8UTR2K4Wd8Wx9+pEGHmtnTMG2ePhRNGtHPajinj7CGMdlJ8r46m/IwPAj9iIdGro0JqUHZhJRYnnIJVv15Y7D4STVIGB367jXk7T2L3h55wMO0jN76xSYpPDl5AY5OUpcQdk81rVkg7dhLHUn6Rm15aWs5SoldHhdSgr4//jgEGetgT6oXuOi/e6imOlpj2r1Rs+TUHccHucuN3Z17HH1WP2YjaYZmZm6BnTyHS0zJwIOko23HajPYhNeRpfQPuVIjgbm8uKyMA9BZ2x+jB/XG15IHc+PwKEXacvYYQN4f2jtqh2dlZAwDu3P6D5STqwfoWsry8HIWFhRCLxdDS0kLPnj1hYWGBAQMGsB2tTfS6aSMlwluujM0e1zVAoPXnv4WNTVJEH7oAZ6uBmDTSElszrrZn1A7N9i+F7NGjO+rq6tmM1CasFfLkyZOIjY1FQUEBGIaRm8fj8WBubo6IiAj84x//YClh2/C1tGDeR19h+p0KEf5dUoU3hwySTfvhf2+g5FENNge6olHKKLyGtM5uqA2ePhXji/WrMW36JPTsKURhQQm++PwbHD54nO14KmOlkCkpKVi1ahW8vLwQFhYGc3Nz6OnpgWEY1NbWori4GL/88gv++c9/4vnz55gyZQobMdWuruE51iRnAQDmjrMHANytfIzvz+Ri1ZQx6G+gh3KRmM2IHY6tnTX09YUw6KWPhSHLYWCgj9BFc7ArPhbaAm0k7U9hO6JKWCnk999/j/fffx/R0dEtzh86dCi8vLzw6aefIi4urlMUsl7SiPAfz+BOhQjB4+zhZNEfTdIXH1Udzfth+uvWbEfskBJ+2A8+n4+d3/8om3b4YBouXD6Bz75cieQDqZBKO85Ra1YO6pSXl2PixIl/O27ChAkoLS1th0Sa9bRegoXxGfi9oBJTR1shzH0kACDhXB7uVIiwxNMRotpnENU+Q029BADw7HkjRLXPIKWPsC/1w659cmUEgGfPGpC0PwX9+/eFrd0QlpK9Gla2kKampjh//jxcXFxeOu7s2bMd/uBOtbgeC+NP4fZ9Eaa/bo013s7g8XgAgKz8e3jeJEXg9hMKr0s4l4eEc3k4HjkNxobC9o7d4T188AgAoKenx3IS1bBSyNDQUCxfvhxVVVXw8PCAhYUFhEIheDwexGKxbB8yLS0Nn332GRsR1aK24bmsjIEudoic5CQ3f5nXaDz9zxax2SNxPT5OzsLkkZaY7GiJPsLu7Rm5Qxk4sD8OpcbjyKHj+PqrLXLzrG0sAQDFRR3rExYrhZw8eTL4fD42b96M48ePy7YYzRiGgYmJCdatW4dp06axEVEt1qdexu37Isx801ahjAAw1Li3wrTmgzrGRkK8MWSgxjN2ZPfvV0JfvyfmfOCP/9kaj5qa/7x3xgPx/qzp+N/Mi6iqeshyStW0WsjZs2ervDAej4eEhASlxnp5ecHLywulpaUoKCiAWCwGwzCy7yHNzMxU/v1cUlD1BGn/LoBQVxuvDTTC8X8XKIx5d6QlC8k6lxXLPsXe/f+DX04dQEJ8EoRCPXy4IAhNjY1YvvRTtuOprNVClpWVtUsAU1NTmJqatsvvak9XCisBAOJnzxF96EKLY6iQbZeeloGZ/qFYGhmKTz9fgWf1z3D+/G/4PDoG+XcU/xHkOh7z12/lO4n6g1+wHaHTGPRBPNsROhWR+G6r817pa4/KykpcvXoVNTU1kEgkHep7HkK4TKVCXrlyBT4+PnB1dUVAQACuX7+Oy5cvw9XVFenp6ZrKSEiXoXQhc3NzMXfuXNTW1mLOnDmy6QYGBhAIBIiMjERmZqZGQhLSVShdyNjYWJiYmODo0aMICQmRnRDu4OCA1NRUWFlZIS4uTmNBCekKlC5kTk4OfHx8oKurq/C9oVAohJ+fH/Lz89UekJCuRKV9SB0dnVbnNTQ00MEdQtpI6UKOGDECaWlpLc6rq6tDcnIyHBzoandC2kLpQi5ZsgR5eXkIDAxESkoKeDwecnNzkZiYCG9vb5SVlSE0NFSTWQnp9FQ6MSArKwvR0dEKZ/H07dsXa9euhYeHh9oDvio6MUB96MQA9XrZiQEqnVzu4uKCX3/9FXl5eSgpKYFUKoWxsTHs7e0hELB+ex5COjyVW8Tj8TBgwAA0NTVBS0sLpqamVEZC1ESlJl28eBExMTHIy8uTm+7k5ITVq1fDzs5OreEI6WqULuT58+exYMECCIVCBAYGwszMDFKpFEVFRTh27BhmzpyJH3/8EcOGDdNkXkI6NaUP6vj5+aGmpgb79++HgYGB3LyHDx/C398fJiYmSl8PqWl0UEd96KCOeqnlao9bt27B399foYwA0KdPH8ycORNXr9INfglpC6UL2a9fP4hEolbnNzU1oVevXmoJRUhXpXQhQ0NDkZiYiHPnzinMu3nzJhISEjBv3jy1hiOkq1H5njohISEYMmQILC0twePxUF5ejhs3bsDAwADXr1/XWFBCugKV7qljaGgIAKitrcW1a9dk05vvnZqdna3ufIR0Ka0W8vTp0+2ZgxACNT9KoLq6Wp2LI6TLUelMnZSUFJw8eRJ1dXVy1z42NTWhtrYWd+/epf1IQtpA6ULu2LEDmzZtgra2NoRCIUQiEQYMGIDHjx+jvr4eurq6CAoK0mRWQjo9pT+yHj58GLa2trhw4QKSkpLAMAwSExORnZ2NTz75BA0NDRgxYoQmsxLS6SldyPLycnh7e0MoFMLU1BQGBgbIzs4Gn8/HzJkzMWnSJM6cNkdIR6V0IQUCgdyjvczNzXH79m3Zz87OzigqKlJrOEK6GqULaWVlhZycHNnPFhYWcgdwnj59ColE0tJLCSFKUrqQPj4+OHz4MCIjI1FXV4fx48cjOzsbW7ZsQXp6OuLj42Fra6vJrIR0ekofZX3//fdRUVGBvXv3QiAQwMPDA++++y62bHnxoEyhUIjIyEiNBSWkK1D56VeNjY1yt+z4/fff8eTJEzg6OqJ3b8UHkLKFrodUH7oeUr3UdpMrAAr3z3n99ddVT0QIaRFrT1AmhChi/QnKhJA/ddonKAt0jNmO0GnU31O8KJ28Ou0+rT/KXq1XexBC2oYKSQiHUCEJ4RAqJCEcQoUkhENeqZCVlZW4evUqampqIJFI6MnJhKiJSoW8cuUKfHx84OrqioCAAFy/fh2XL1+Gq6sr0tPTNZWRkC5D6ULm5uZi7ty5qK2txZw5c2TTDQwMIBAIEBkZiczMTI2EJKSrULqQsbGxMDExwdGjRxESEoLm8wkcHByQmpoKKysrxMXFaSwoIV2B0oXMycmBj48PdHV1wePx5OYJhUL4+fkhPz9f7QEJ6UpU2ofU0dFpdV5DQwMd3CGkjZQu5IgRI5CWltbivLq6OiQnJ8PBwUFtwQjpipQu5JIlS5CXl4fAwECkpKSAx+MhNzcXiYmJ8Pb2RllZGUJDQzWZlZBOT6WrPbKyshAdHa1waVbfvn2xdu1aeHh4qD3gq6KrPdSHrvZQr5dd7aHy5VcMw+DGjRsoLS2FVCqFsbEx7O3tFe4kwDYqpPpQIdVLrYXsKKiQ6kOFVK+XFVLpzZqyt/RITExUdpGEkL9QupAt3dJDKpVCJBKhoaEBxsbGsLa2Vms4QroapQvZ2gNcm5qacOrUKaxZswbz5s1TWzBCuqI2X37F5/Ph4eEBX19fxMTEqCMTIV2W2q6HHDx4MG7duqWuxRHSJamlkBKJBKmpqZy6czkhHVGbj7JKJBIUFhbi6dOnCAsLU1swQrqiNh1lBV7sQ1paWmLy5MmYOXOm2oIR0hUpfWJAdXU1jIyMNJ1HbejEAPWhEwPUSy03Svbx8cG2bdvUEogQ0jKlC1ldXY0+ffpoMgshXZ7ShZwyZQqSkpLoITyEaJDSB3W0tLRQUFAAT09PmJmZoXfv3tDSku8zPY6OkLZRupBZWVkwNDQE8OJ2Hffu3dNYKEK6Krr8ivwtOsqqXq90lDUqKgpXr17VSCBCSMtaLeSRI0dQUlLSnlkI6fLoYTssc3CwQ524EJ+sXcp2lA4h67crmL0wEk7jp+L1idMwPzwKV6/flBtz41Y+5oevxusTpsLZ3QeLV0SjsLhjfDtAhWQRn8/Hrp2bX3q/W/Kn33NyEbpsLWrEtVgSMgcL585Cafl9fPDRClzLuw0AKCwuw9yPVuLOH4UInTsTIXMCcO3GbcxetAxVDx6xvAZ/76VHWbOzs9HU1KTSAqdOndqmQF3JqpVhGDbUhu0YHcaG2DgM6NcXP+3YjO66ugCA97wm4L2ZIYiNS8DO2HXYc+AI6urrkbBtI+xshgAAxowegffnRyAx6QgiP5rP5ir8rZcW8sCBAzhw4IBSC2IYBjwejwqpJHt7W6yOWoIv18Xi889WsB2H8548rcHtu4WYE+AjKyMA9DEyhJOjAy5e/j8AQNm9Chj20peVEQAc7F5DLwN95BcUtXdslb20kH5+fhg5cmR7Zeky+Hw+du7YhFOnzmPvT4eokEoQ6vVA2r4dcmVs9vjxU/D5fACAuYkxLmX/G9WixzAy7AXgRZlrxGL07c39iyNeWkgnJydMmTKlvbJ0GSuWL4b1EAtMnzEPAgGf7TgdAp/Ph7mp4nfLt+8WIudaHlycRwMAgmfNwNms37Di0w1YHhYCHg+I2bIT2gJtzPJ9r71jq4xbdzfuAoYOtcGajyOwJHwNysvvw9zchO1IHVZdXT1W/78X93GaF+gLABg4oB8+nO2PdZu2YfqcRQAAPl8Lm774WO5jLFexVsjKykqVxvfv319DSdqPlpYWdu3YhKys37Fr909sx+nQ6p89w0crP8PtuwWYH+SP1x2HAwC++z4RcQn74OToAN/3vNAklSLpyHEsW7se//ryY7i+9QbLyV+u1UJOmzYNZmZmGvvFEyZMUOkI7s2bN/9+EMdFLluI4cOHYpzrNPTu/eK8YENDAwBAjx7d0bu3IaqrH6OTns2oNk9rxFi8Iho5uXmYNtkD4QvmyKb/sO8ghtlaY1fsetl+pdfEcQiYF47oDd/i1zGjOP01U6uFXL9+vUZ/cXJyMhYsWACJRIJly5Zx7tkgmuDp4Ypu3brh0sV0hXmRyxYhctkiWFk7o7iDfInNhkeix1jwz49xK78Avt5e+GR5mOwBwsVl5ZBInmOSu6usjACgLRDgXQ83bNq2CwXFZbC1bv1cUrax1gI7OzvEx8fD19cXDx48wKJFi9iK0m6Wr/gchv858tesX/8+2JOwBXt+PIgffzyIiooHLKXjvtraOlkZZ/tPw4olIXLzdbRfbPmamhQfHNz8MGGG4fZDhVndLFlaWmLp0qX45ptvEBAQ0KHu2fMq/i/nmsK05oM6hYXFOHWarqp4mS82bcOt/AIE+norlBEAhliYoV+f3jia/itmzXgP3bq9KGhDgwSpP2fAsJc+hlgObufUqmH9c2JAQAA9E4T8rT+KSnDs51PoKdSDrbUVjv2i+GiLKZ7jsXrpQixdsw4BH4bDZ7InpFIpjqSdRGFxGdavjYQ2x3eNWE/H5/MxZswYtmMQjsv+z6eLGnEt1qzb1OKYKZ7jMXGcC3b860ts/+EnfBsXDwCwsxmC7TGf4603nNor7iujC5TJ36ILlNVLLbeBJIRoHhWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUISwiFUSEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHAIFZIQDqFCEsIhVEhCOIQKSQiHUCEJ4RAqJCEcQoUkhEOokIRwCBWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFJIRDqJCEcEinfYIyIR0RbSEJ4RAqJCEcQoUkhEOokIRwCBWSEA6hQhLCIVRIQjiECkkIh1AhCeEQKiQhHEKFZElaWhreffddDB8+HF5eXkhJSWE7Uod38+ZNDBs2DBUVFWxHeWVUSBacOHECkZGRcHFxwdatWzFmzBisXLkSP//8M9vROqyCggIsWLAAjY2NbEdpEzq5nAXu7u6wt7fH5s2bZdMiIiJw+/ZtnDhxgsVkHU9jYyOSkpLwzTffQFtbG48fP0ZmZiYGDBjAdrRXQlvIdlZaWoqSkhJ4eHjITff09ERBQQFKS0tZStYxXblyBTExMQgODkZkZCTbcdqMCtnOCgoKAAAWFhZy083NzQEAhYWF7Z6pI7OyskJGRgY++ugj8Pl8tuO0mYDtAF1NTU0NAEAoFMpN19PTAwCIxeJ2z9SR9enTh+0IakVbyHbWvMvO4/FanK6lRf9LujL6v9/OevbsCUBxS1hbWys3n3RNVMh21rzvWFJSIje9uLhYbj7pmqiQ7czc3BwmJiYK3zmePHkSgwcPxqBBg1hKRriADuqwYPHixYiKioKBgQFcXV1x+vRpnDhxQu57SdI1USFZ4OPjA4lEgt27dyM5ORmmpqbYsGEDJk2axHY0wjI6U4cQDqF9SEI4hApJCIdQIQnhECokIRxChSSEQ6iQhHAIFbINVq1ahddee03uPzs7O4waNQq+vr44cuRIu+QYP348goKCZD8HBQVh/PjxKi9HLBajurpabbma35+2jlHn69prea+KTgxQg6ioKBgaGgJ4cdWGWCxGamoqVq1aBZFIhODg4HbNExoaivr6epVec/36dSxcuBAxMTFwdnbWUDLyd6iQajBx4kSYmJjITZsxYwYmTZqErVu3IjAwEDo6Ou2Wx8XFReXX3LlzB1VVVRpIQ1RBH1k1RFdXF+PHj4dYLEZ+fj7bcUgHQYXUoOaLkJuamgC82Ndbs2YNVq9eDQcHB7zzzjuyfbacnBzMnTsXjo6OcHR0RHBwMHJzcxWWmZ6eDm9vbwwfPhyTJ0/GpUuXFMa0tA/5xx9/IDw8HM7Ozhg9ejSCgoKQnZ0NAPjuu+8QFRUFAJg9e7bcaysqKrBixQq88cYbcHBwwNSpU5GamqrwO69fv47g4GA4Ojri7bffRmJi4qu8ZQCAixcvYv78+XB2dsawYcPw9ttv45NPPsHTp08Vxubk5GD69OlwcHCAh4cH4uPjFcYouw5cQB9ZNUQqleLy5cvQ0dGBlZWVbPrx48dhYWGBjz/+GA8fPoSRkRGysrKwYMEC2NraIjw8HBKJBIcPH8asWbPwww8/wMnJCQBw+PBhREVFwdHREcuXL0dxcTFCQ0MhlUphbGzcapaioiL4+flBIBAgMDAQRkZG2L9/P+bOnYu9e/fC3d0dDx48QFJSEkJDQ+Hg4AAAqKyshK+vLxiGQVBQEAwMDHDq1CksX74cVVVVmD9/PgAgPz8fQUFB0NfXx6JFi/D8+XNs3bpV9g+RKs6fP48PP/wQo0aNwpIlS8Dj8ZCVlYWkpCQ8f/4c69evlxsfHByMiRMnwsfHBxkZGVi/fj1qamoQFham0jpwBkNe2cqVKxkbGxvmxo0bzKNHj5hHjx4xVVVVTE5ODhMeHs7Y2Ngw69atk413c3NjbG1tmeLiYtm0pqYmZsKECUxAQADT2Ngom15bW8u4u7sz3t7eDMMwTGNjIzN27Fhm+vTpjEQikY07dOgQY2NjwwQGBsqmBQYGMm5ubrKfw8PDmeHDhzNFRUWyadXV1czo0aOZJUuWyC3n0qVLcus3ZswYprKyUm69ly5dytjb2zMPHz5kGIZhwsLCmJEjRzL37t2Tjbl79y5jb2/P2NjYKPUeNps3bx7j5ubGNDQ0yI3z8/NjHB0dFV63YcMGufdy9uzZjL29PVNdXa3SOvw1B1voI6saTJs2DWPHjsXYsWPx1ltvwd/fH6dOnUJQUBCWLVsmN9bMzAxmZmayn/Py8lBaWoqJEyfiyZMnqK6uRnV1NZ49ewY3NzfcvHkTFRUVuHHjBh49egQfHx9oa2vLXu/t7Q0DA4NWs0mlUmRmZmLcuHGyO9sBgKGhIX766SesWbOm1ddlZGTAyckJAoFAlqu6uhoeHh6QSCTIysqCVCrFuXPnMG7cOAwcOFD2eisrK7z11lsqv5dxcXE4dOiQ3EEwkUgEoVCIuro6hfH/vYXT0tJCYGAgJBIJLly4oPQ6cAl9ZFWDr7/+Wnb3My0tLejr68PKygrdunVTGNu7d2+5n5tv5bFx40Zs3LixxeXfv39fdnv8/y4zAPD5fLmi/dXjx49RV1fX4hgbG5tWXycSiVBTU4OMjAxkZGS0mqt5+X/NBQCWlpY4ffp0q7+jJXw+H6WlpYiNjcXdu3dRUlKCysrKFsf26tULRkZGctNMTU0BAOXl5UqvA5dQIdVg1KhRCl97tOav9w6VSqUAgPDwcIwcObLF11haWsr+KBsaGhTmNy+jJc37careza75dZ6enggICGhxTPMf/6vkas3+/fsRHR0NCwsLODk5wcPDAyNGjMCePXtw7NgxubF/vXMfIH/3PlXXgQuokCxrPhjTo0cPvPnmm3LzcnNz8eTJE+jq6sr+cIqKiuTGMAyD8vJyWFtbt7h8Q0ND6Orqym6i9d927dqFhw8fYuXKlQrzjIyM0L17dzQ2NirkunfvHvLy8tC9e3cYGhpCKBQq5AKAsrKyVte7JQ0NDfjqq6/g7OyM3bt3QyD4888zNjZWYfyTJ08gFovl7nHbnMPMzEzpdeAS2odkmb29Pfr27Ys9e/bIbgUJvDiNLSIiAlFRUeDz+Rg6dCiMjY2xb98+ubNwjh8/DpFI1OryBQIBXFxckJmZKffx7MmTJ9i1a5fsI3PzFrR5qyYQCPDOO+8gMzMTt27dklvmV199hcWLF0MkEoHH48Hd3R3nzp3DnTt3ZGPKyspw9uxZld6LZ8+eob6+HoMHD5Yr482bN3H58mUAkHuYjlQqxcGDB2U/NzY2IiEhAT169MDYsWOVXgcuoS0ky7S1tbF27VpERETAx8cHM2bMQLdu3ZCcnIx79+4hJiZG9se5du1aLF68GP7+/pg+fToqKyuxd+9e9OrV66W/Y9myZfD19YWvry9mzZoFoVCIAwcOoK6uDhEREQAg2xfbt28fHj58iClTpiAyMhK//fYbZs2ahVmzZmHQoEE4e/Yszpw5A39/f9lWOTw8HGfPnkVQUBA++OAD8Pl87NmzB3p6epBIJEq/FwYGBhgxYgQOHz4MoVAICwsL5OfnIzk5WfYPRm1trewgVvfu3fHtt9/i/v37MDMzQ3p6OnJychAdHS27v62y68AVVEgO8PT0xO7du7F9+3Zs27YNWlpasLa2xvbt2+Hm5iYb5+bmhri4OHz33XfYtGkT+vfvjy+//BJ79+596fKtrKyQlJSETZs2YefOndDS0sLw4cOxYcMG2R/k2LFj4eXlhTNnzuDSpUvw8PCAmZkZDhw4gG+//VZWYFNTU0RFRcmdzD5w4EDs27cPGzduxM6dO6GjowNfX18AL46aqiI2Nhbr16/HoUOHIJFIYGxsjJCQEFhZWSEsLAyXLl2Cp6cnAEBfXx8bNmzAunXrsHfvXpibm+Prr7/Ge++9J1uesuvAFXSTK0I4hPYhCeEQKiQhHEKFJIRDqJCEcAgVkhAOoUISwiFUSEI4hApJCIdQIQnhkP8POVzQkARgFFwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                     annot=True, # Annotate the boxes \n",
    "                     cbar=False)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label');\n",
    "\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got a bit more information here but... our numbers are looking a little off.\n",
    "\n",
    "After a little digging, we figure out the version of Matplotlib we're using broke Seaborn plots.\n",
    "\n",
    "GitHub issue: <a href=\"https://github.com/matplotlib/matplotlib/issues/14675\"Heatmaps are being truncated when using with seaborn</a>\n",
    "\n",
    "But luckily, we found <a href=\"https://stackoverflow.com/questions/56942670/matplotlib-seaborn-first-and-last-row-cut-in-half-of-heatmap-plot\">a few potential solutions on Stack Overflow</a>.\n",
    "\n",
    "<b>Note</b>: The underlying issue here is the version of Matplotlib I'm using (3.1.1) is what's causing the error. By the time you read this, a newer, fixed version may be out.\n",
    "\n",
    "Since we probably want to make a few confusion matrices, it makes sense to make a function for plotting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                     annot=True, # Annotate the boxes\n",
    "                     cbar=False)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    \n",
    "    # Fix the broken annotations (this happened in Matplotlib 3.1.1)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5);\n",
    "    \n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ideal confusion matrix no values out of the diagonal. This means all of models predictions match the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create perfect confusion matrix\n",
    "perfect_conf_mat = confusion_matrix(y_test, y_test)\n",
    "plot_conf_mat(perfect_conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn has an implementation of plotting a confusion matrix in <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix\">plot_confusion_matrix()</a>, however, the documentation on it isn't complete (at the time of writing).\n",
    "\n",
    "And trying to import it returns an error.\n",
    "\n",
    "You can try to use it but beware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Returns an error.... (at time of writing)\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf, X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    "The final major metric you should consider when evaluating a classification model is a classification report.\n",
    "\n",
    "A classification report is more so a collection of metrics rather than a single one.\n",
    "\n",
    "You can create a classification report using Scikit-Learn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\">classification_report()</a> function.\n",
    "\n",
    "Let's see one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.85      0.88      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns four columns: precision, recall, f1-score and support.\n",
    "\n",
    "The number of rows will depend on how many different classes there are. But there will always be three rows labell accuracy, macro avg and weighted avg.\n",
    "\n",
    "Each term measures something slightly different:\n",
    "\n",
    "- <b>Precision</b> - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "- <b>Recall</b> - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "- <b>F1 score</b> - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "- <b>Support</b> - The number of samples each metric was calculated on.\n",
    "- <b>Accuracy</b> - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n",
    "- <b>Macro avg</b> - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into effect. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n",
    "- <b>Weighted avg</b> - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples).\n",
    "\n",
    "When should you use each?\n",
    "\n",
    "It can be tempting to base your classification models perfomance only on accuracy. And accuracy is a good metric to report, except when you have very imbalanced classes.\n",
    "\n",
    "For example, let's say there were 10,000 people. And 1 of them had a disease. You're asked to build a model to predict who has it.\n",
    "\n",
    "You build the model and find your model to be 99.99% accurate. Which sounds great! ...until you realise, all its doing is predicting no one has the disease, in other words all 10,000 predictions are false.\n",
    "\n",
    "In this case, you'd want to turn to metrics such as precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one case\n",
    "\n",
    "disease_preds = np.zeros(10000) # every prediction is 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true, \n",
    "                                   disease_preds, \n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here, we've got an accuracy of 0.9999 (99.99%), great precision and recall on class 0.0 but nothing for class 1.0.\n",
    "\n",
    "Ask yourself, although the model achieves 99.99% accuracy, is it useful?\n",
    "\n",
    "To summarize:\n",
    "\n",
    "- Accuracy is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1)\n",
    "- Precision and recall become more important when classes are imbalanced.\n",
    "- If false positive predictions are worse than false negatives, aim for higher precision.\n",
    "- If false negative predictions are worse than false positives, aim for higher recall.\n",
    "\n",
    "### 4.2.2 Regression model evaluation metrics\n",
    "\n",
    "Similar to classification, there are <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\">several metrics you can use to evaluate your regression models</a>.\n",
    "\n",
    "We'll check out the following.\n",
    "\n",
    "- <b>R^2 (pronounced r-squared) or coefficient of determination</b> - Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1.\n",
    "- <b>Mean absolute error (MAE)</b> - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
    "- <b>Mean squared error (MSE)</b> - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
    "Let's see them in action. First, we'll bring down our regression model code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R^2 Score (coefficient of determination)\n",
    "\n",
    "Once you've got a trained regression model, the default evaluation metric in the score() function is R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the models R^2 score\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
